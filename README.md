# NBA_Betting_Over-Under

I, alongside two classmates at Cornell Tech, developed a machine learning pipeline to predict NBA game scores relative to the betting over/under line. Preprocessing focused on creating a clean dataset by isolating games from the 2013 season onward, accounting for the NBA’s evolving playstyle. Feature engineering included calculating 15-game averages for points scored, point differentials, and win percentages to capture recent performance trends. Categorical features like team and season identifiers were one-hot encoded, while binary encoding of player participation captured individual contributions. Initial experiments evaluated Lasso, ElasticNet, and Random Forest, both with and without one-hot encoding of player and season data. ElasticNet emerged as a strong contender with a Mean Squared Error (MSE) of 333.3, leading us to select it for further analysis. Using a dataset of 37,105 rows, we randomly sampled 1,000 rows for testing, leaving 36,105 for training. ElasticNet achieved an accuracy of 53.1%, exceeding the profitability threshold of 52.4% in sports betting. We implemented hyperparameter tuning for ElasticNet, Lasso, Random Forest, and XGBoost, optimizing parameters like alpha and L1-ratio for ElasticNet. The final evaluation highlighted K-Nearest Neighbors (KNN) as the top-performing model with an accuracy of 52.9%, closely followed by ElasticNet and Random Forest. These results were strong given our limited experience with this approach. We plan to continue refining our work beyond this final submission, with a particular focus on pre-processing our data to enhance our chosen model’s accuracy.
